"""
This script runs a simple MC EasyVVUQ Campign on the analytical Sobol g-function.
The EasyVVUQ data frame is then read by EasySurrogate, and a neural network is trained
on the input-output data generated by EasyVVUQ.
"""

import os
import easysurrogate as es
import chaospy as cp
import numpy as np
import easyvvuq as uq
import matplotlib.pyplot as plt
from easyvvuq.actions import CreateRunDirectory, Encode, Decode, ExecuteLocal, Actions

plt.close('all')

# author: Wouter Edeling
__license__ = "LGPL"

# the absolute path of this file
HOME = os.path.abspath(os.path.dirname(__file__))

########################
# EasyVVUQ MC Campaign #
########################

# number of uncertain parameters
D = 5

# Define parameter space
params = {}
for i in range(D):
    params["x%d" % (i + 1)] = {"type": "float",
                               "min": 0.0,
                               "max": 1.0,
                               "default": 0.5}
params["D"] = {"type": "integer", "default": D}
params["out_file"] = {"type": "string", "default": "output.csv"}
output_filename = params["out_file"]["default"]
output_columns = ["f"]

# create encoder, decoder, and execute locally
encoder = uq.encoders.GenericEncoder(template_fname=HOME + '/model/g_func.template',
                                     delimiter='$',
                                     target_filename='in.json')
decoder = uq.decoders.SimpleCSV(target_filename=output_filename,
                                output_columns=output_columns)
execute = ExecuteLocal('{}/model/g_func.py in.json'.format(os.getcwd()))
actions = Actions(CreateRunDirectory('/tmp'),
                  Encode(encoder), execute, Decode(decoder))

# uncertain variables
vary = {}
for i in range(D):
    vary["x%d" % (i + 1)] = cp.Uniform(0, 1)

# MC sampler
my_sampler = uq.sampling.MCSampler(vary=vary, n_mc_samples=50)

# EasyVVUQ Campaign
campaign = uq.Campaign(name='g_func', params=params, actions=actions)

# Associate the sampler with the campaign
campaign.set_sampler(my_sampler)

# Execute runs
campaign.execute().collate()

# get the EasyVVUQ data frame
data_frame = campaign.get_collation_result()

##############################
# EasySurrogate GPR campaign #
##############################

# Create an EasySurrogate campaign
surr_campaign = es.Campaign()

# This is the main point of this test: extract training data from EasyVVUQ data frame
features, samples = surr_campaign.load_easyvvuq_data(campaign, qoi_cols='f')

# Create gaussian process regression surrogate
surrogate = es.methods.GP_Surrogate(n_in=D)

# Number of training iterations
N_ITER = 10

# The latter fraction of the data to be kept apart for testing
TEST_FRAC = 0.3

# Train the GPR
surrogate.train(features, 
                samples['f'], 
                n_iter=N_ITER,
                test_frac=TEST_FRAC,
                )

# get some useful dimensions of the GPR surrogate
dims = surrogate.get_dimensions()

# evaluate the GPR surrogate on the training data

training_predictions     = np.zeros([dims['n_train'], dims['n_out']])
training_predictions_std = np.zeros([dims['n_train'], dims['n_out']])
for i in range(dims['n_train']):
    training_predictions[i] = surrogate.predict(features[i].reshape(-1,1))[0]


# print the relative training error

error_train = np.linalg.norm(training_predictions - samples['f'][0:dims['n_train']]) /\
    np.linalg.norm(samples['f'][0:dims['n_train']])
print("Relative error on training set = %.3f percent" % (error_train * 100))


# evaluate the GPR surrogate on the test data

test_predictions = np.zeros([dims['n_test'], dims['n_out']])
for count, i in enumerate(range(dims['n_train'], dims['n_samples'])):
    test_predictions[count] = surrogate.predict(features[i].reshape(-1,1))[0]

# estimate image of the function
qoi_avg = test_predictions.mean()

print('average QoI value from test set: {0} and predeicted: {1}'.format(
    qoi_avg,
    samples['f'][dims['n_train']:].mean()))


# print the relative test error

error_test = np.linalg.norm(test_predictions - samples['f'][dims['n_train']:]) /\
    np.linalg.norm(samples['f'][dims['n_train']:])
print("Relative error on test set = %.3f percent" % (error_test * 100))


# produce a sample close to average predicted value
feature_names = ["x%d" % (i + 1) for i in range(D)]
x_new = surrogate.train_sequentially(n_iter=1, feats=feature_names, target=qoi_avg, acquisition_function='poi_sq_dist_to_val') 
print("the new sample is x={0} with y_surr={1}".format(
    x_new, surrogate.predict(x_new.reshape(-1, 1))[0]))
