{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba5f5c75",
   "metadata": {},
   "source": [
    "# Reduced closure models for Navier Stokes\n",
    "\n",
    "\n",
    "Consider a turbulent fluid flow governed by the 2D Navier-Stokes equations, written as the forced-dissipative vorticity equations for two-dimensional incompressible flow. The governing equations then read:\n",
    "\n",
    "\\begin{align}\n",
    " \\frac{\\partial\\omega}{\\partial t} + J(\\Psi,\\omega) = \\nu\\nabla^2\\omega + \\mu\\left(F - \\omega\\right), \\nonumber\\\\\n",
    " %\n",
    " \\nabla^2\\Psi = \\omega.\n",
    "\\end{align}\n",
    "\n",
    "Here, $\\omega$ is the vertical component of the vorticity, defined from the curl of the velocity field ${\\bf V}$ as $\\omega:={\\bf e}_3\\cdot\\nabla\\times{\\bf V}$, where ${\\bf e}_3:=\\left(0,0,1\\right)^T$. The stream function $\\Psi$ relates to the horizontal velocity components by the well-known relations:\n",
    "\n",
    "* $u = -\\partial\\Psi/\\partial y$ \n",
    "* $v = \\partial\\Psi/\\partial x$\n",
    "\n",
    "As in [1], the forcing term is chosen as the single Fourier mode $F = 2^{3/2}\\cos(5x)\\cos(5y)$. The system is fully periodic in x and y directions over a period of $2\\pi L$, where $L$ is a user-specified length scale, chosen as the earth's radius ($L = 6.371\\times 10^6 [m]$). The inverse of the earth's angular velocity $\\Omega^{-1}$ is chosen as a time scale, where $\\Omega=7.292\\times 10^{-5}[s^{-1}]$. The values of $\\nu$ and $\\mu$ chosen such that a Fourier mode at the smallest retained spatial scale is exponentially damped with an e-folding time scale of 5 and 90 days respectively. For more details on the numerical setup we refer to [1].\n",
    "\n",
    "Finally, **the key term is the Jacobian**, i.e. the nonlinear advection term defined as;\n",
    "\n",
    "\\begin{align}\n",
    " J(\\Psi, \\omega) := u\\frac{\\partial\\omega}{\\partial x} + v\\frac{\\partial\\omega}{\\partial y} = \n",
    " \\frac{\\partial\\Psi}{\\partial x}\\frac{\\partial\\omega}{\\partial y} - \\frac{\\partial\\Psi}{\\partial y}\\frac{\\partial\\omega}{\\partial x}\n",
    "\\end{align}\n",
    "\n",
    "### Discretization\n",
    "\n",
    "We solve by means of a spectral method, where we apply a truncated Fourier expansion:\n",
    "\n",
    "\\begin{align}\n",
    " \\omega(x, y, t) \\approx \\tilde{\\omega}(x, y, t)\n",
    "%\n",
    " = \\sum_{{\\bf k}} \\hat{\\omega}_{\\bf k}(t) e^{\\underline{i}(k_1 x + k_2 y)}, \\nonumber\\\\\n",
    "%\n",
    " \\Psi(x, y, t) \\approx \\tilde{\\Psi}(x, y, t)\n",
    " = \\sum_{{\\bf k}} \\hat{\\Psi}_{\\bf k}(t) e^{\\underline{i}(k_1 x + k_2 y)}.  \n",
    "\\end{align}\n",
    "\n",
    "The sum is taken over the components $k_1$ and $k_2$ of the wave number vector ${\\bf k}:=(k_1, k_2)^T$, and $-K' \\leq k_j \\leq K'$, $j=1,2$. These decompositions are inserted in the governing equations, and solved for the Fourier coefficients $\\hat{\\omega}_{\\bf k}$, $\\hat{\\Psi}_{\\bf k}$ by means of the real Fast Fourier Transform. To avoid the aliasing problem in the nonlinear term $J$, we use the well-known 2/3 rule, such that in practice the maximum resolved wave number is $K$, where $K \\leq 2K'/3$ [2]. \n",
    "\n",
    "To advance the solution in time we use the second-order accurate AB/BDI2 scheme, which results in the following discrete system of equations [2];\n",
    "\n",
    "\\begin{align}\n",
    " \\frac{3\\hat{\\omega}^{n+1}_{\\bf k} - 4\\hat{\\omega}^{n}_{\\bf k} + \\hat{\\omega}^{n-1}_{\\bf k}}{2\\Delta t} + 2\\hat{J}^n_{\\bf k} - \\hat{J}^{n-1}_{\\bf k} = -\\nu k^2 \\hat{\\omega}^{n+1}_{\\bf k} + \\mu\\left(\\hat{F}_{\\bf k} - \\hat{\\omega}^{n+1}_{\\bf k}\\right), \\nonumber\\\\\n",
    " %\n",
    " -k^2\\hat{\\Psi}^{n+1}_{\\bf k} - \\hat{\\omega}^{n+1}_{\\bf k} = 0.\n",
    "\\end{align}\n",
    "\n",
    "Here, $\\Delta t$ is the time step and $\\hat{J}^n_{\\bf k}$ is the Fourier coefficient of the Jacobian at time level $n$, and $k^2:=k_1^2 + k_2^2$.\n",
    "\n",
    "### Multiscale decomposition\n",
    "\n",
    "Resolving all turbulent scales is very expensive, if not practically impossible. Therefore, a multiscale decompostion is performed, splitting the full solution into (large) resolved ($\\mathcal{R}$) and (small) unresolved components ($\\mathcal{U}$). The system becomes computationally tractable by only directly computing the resolved components. We use a spectral filter to obtain the resolved solution;\n",
    "\n",
    "\\begin{align}\n",
    " \\hat{\\omega}_{\\bf k}^{\\mathcal{R}} = \\mathcal{\\hat{T}}^{\\mathcal{R}}\\hat{\\omega}_{\\bf k},\\quad\\quad\n",
    " %\\hat{\\omega}_{\\bf k}^{\\mathcal{U}} = \\mathcal{\\hat{T}}^{\\mathcal{U}}\\hat{\\omega}_{\\bf k},\n",
    "\\end{align}\n",
    "\n",
    "The spectral filter $\\mathcal{\\hat{T}}^{\\mathcal{R}}$ simply zeroes out any Fourier coefficient above a certain cut-off wave number, it will be depicted below. Applying the filter to the governing equations results in the following resolved-scale transport equation:\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\partial\\omega^{\\mathcal{R}}}{\\partial t} + \\mathcal{T}^{\\mathcal{R}} J(\\Psi, \\omega) = \\nu\\nabla^2\\omega^{\\mathcal{R}} + \\mu\\left(F - \\omega^{\\mathcal{R}}\\right). \n",
    "\\end{align}\n",
    "\n",
    "Note that $\\omega^{\\mathcal{R}} = \\mathcal{T}^{\\mathcal{R}}\\omega = \\mathrm{IFFT}\\left(\\mathcal{\\hat{T}}^{\\mathcal{R}}\\hat{\\omega}_{\\bf k}\\right)$, the inverse FFT of the filtered Fourier coefficients. \n",
    "\n",
    "As mentioned, the key term is the Jacobian, since due to its non linearity, $\\mathcal{T}^{\\mathcal{R}} J\\left(\\Psi, \\;\\omega\\right)\\neq \\mathcal{T}^{\\mathcal{R}} J\\left({\\Psi}^{\\mathcal{R}},\\; {\\omega}^\\mathcal{R}\\right)$. We therefore write;\n",
    "\n",
    "\\begin{align}\n",
    "\\boxed{\n",
    "\\overline{r}:=\\mathcal{T}^{\\mathcal{R}} r: = \\mathcal{T}^{\\mathcal{R}}\\left[J(\\Psi, \\omega) -  J\\left({\\Psi}^{\\mathcal{R}},\\; {\\omega}^{\\mathcal{R}}\\right)\\right]}\n",
    "\\end{align}\n",
    "\n",
    "such that $\\overline{r}$ is the **exact** subgrid-scale term, sometimes referred to as the **eddy forcing**.\n",
    "\n",
    "### Goal\n",
    "\n",
    "Since $\\overline r$ depends upon the unfiltered $\\Psi$ and $\\omega$, it is an unclosed quantity. We can therefore **only compute it directly by running a high-resolution (HR) simulation next to the resolved governing equations**. This approach has the following pros and cons:\n",
    "\n",
    "* ***pros***: we generate \"gold standard\" $\\overline r$ snapshots, since we are using the exact sgs expression. The $\\omega^{\\mathcal{R}}$ fields will be *locally the same as the filtered HR solution*: $\\omega^{\\mathcal{R}} = \\mathcal{T}^{\\mathcal{R}}\\omega$.\n",
    "\n",
    "* ***cons***: if we wish to use the $\\overline r$ snapshots to train a data-driven surrogate SGS model, the target $\\mathcal{T}^{\\mathcal{R}} r$ is still a spatio-temporal `N_LR x N_LR` field, where `N_LR` is the number of points in 1 spatial direction of the resolved (low-resolution) model. This can be modelled with a CNN of course, but this is a black box approach, and moreover, in 3D the target would be a `N_LR x N_LR x N_LR` SGS field, which requires more (GPU) memory.\n",
    "\n",
    "However, if we restrict our ambition to **computing the (long-term) global \"climate\" of the model**, this would be equivalent to *a-priori* defining a set of scalar (time-dependent) Quantities of Interest (QoIs): \n",
    "\n",
    "\\begin{align}\n",
    "\\mathcal{Q} = \\{Q_1(t),\\cdots, Q_d(t)\\}\n",
    "\\end{align}\n",
    "\n",
    "Consider a general time-dependent quantity of interest $Q_i(t)$, normalised by the area of the flow domain, as;\n",
    "\n",
    "\\begin{align}\n",
    " Q_i(t) = \\left(\\frac{1}{2\\pi}\\right)^2\\int_0^{2\\pi}\\int_0^{2\\pi} q_i(\\omega^{\\mathcal{R}}, \\psi^{\\mathcal{R}}; x, y, t)\\; \\mathrm{d}x\\mathrm{dy},\n",
    "    \\quad i=1,\\cdots,d.\n",
    "\\end{align}\n",
    "\n",
    "Then, $Q_i$ is governed by the following ordinary differential equation (ODE):  \n",
    "\n",
    "\\begin{align}\n",
    "    \\frac{\\mathrm{d}Q_i}{\\mathrm{d}t} &= \\left(\\frac{1}{2\\pi}\\right)^2\\int_0^{2\\pi}\\int_0^{2\\pi} \\frac{\\partial q_i}{\\partial \\omega^{\\mathcal{R}}} \\frac{\\partial\\omega^{\\mathcal{R}}}{\\partial t} + \n",
    "    \\frac{\\partial q_i}{\\partial \\psi^{\\mathcal{R}}} \\frac{\\partial\\psi^{\\mathcal{R}}}{\\partial t} \\; \\mathrm{d}x\\mathrm{dy}  \\nonumber\\\\\n",
    "   &= \\left(\\frac{\\partial q_i}{\\partial \\omega^{\\mathcal{R}}}, \\frac{\\partial\\omega^{\\mathcal{R}}}{\\partial t}\\right) + \\left(\\frac{\\partial q_i}{\\partial \\psi^{\\mathcal{R}}}, \\frac{\\partial\\psi^{\\mathcal{R}}}{\\partial t}\\right),\n",
    "   \\quad i=1,\\cdots,d.\n",
    "\\end{align}\n",
    "\n",
    "Common QoIs include the energy $Q_1 = E^{\\mathcal{R}}:=-\\frac{1}{2}(\\Psi^{\\mathcal{R}}, \\omega^{\\mathcal{R}})$ and enstrophy $Q_2 = Z^{\\mathcal{R}}:=\\frac{1}{2}(\\omega^{\\mathcal{R}}, \\omega^{\\mathcal{R}})$, for which the above can be written as;\n",
    "\n",
    "\\begin{align}\n",
    " \\frac{\\mathrm{d}E^{\\mathcal{R}}}{\\mathrm{d}t} &= -\\left(\\Psi^{\\mathcal{R}}, \\frac{\\partial\\omega^{\\mathcal{R}}}{\\partial t}\\right) = \\cdots + \\left(\\Psi^{\\mathcal{R}}, \\overline{r}\\right)\\\\\n",
    " \\frac{\\mathrm{d}Z^{\\mathcal{R}}}{\\mathrm{d}t} &= \\left(\\omega^{\\mathcal{R}}, \\frac{\\partial\\omega^{\\mathcal{R}}}{\\partial t}\\right) = \\cdots - \\left(\\omega^{\\mathcal{R}}, \\overline{r}\\right)\n",
    "\\end{align}\n",
    "\n",
    "By inserting expression for $\\partial\\omega^\\mathcal{R}/\\partial t$, the right-hand sides of these ODEs will contain a number of terms ($\\cdots$), but we will focus on the term generated by the SGS term. As will be shown below, the exact SGS term $\\overline{r}$ will leads to $E^\\mathcal{R}(t)$ and $Z^\\mathcal{R}(t)$ trajectories that follow the energy and enstrophy of the filtered HR model. The question we ask is:\n",
    "\n",
    "<p style=\"text-align: center;\">\n",
    "<i>Can we also get accurate $E^\\mathcal{R}(t)$ and $Z^\\mathcal{R}(t)$ results with a different SGS term $\\underline{r}$, that is only unclosed at the ODE level, rather than the (filtered) PDE level?</i>\n",
    "</p>\n",
    "\n",
    "We call $\\underline{r}$ a **reduced closure model**, and assume the following expansion;\n",
    "\n",
    "\\begin{align}\n",
    "    \\boxed{\\underline{r} = \\sum_{i=1}^d\\tau_i(t)P_i(x, y, t).}\n",
    "\\end{align}\n",
    "\n",
    "The $\\tau_i$ are the unclosed time series we wish to extract from the training data, $P_i$ are resolved spatio-temporal basis functions, and $d$ is the number of small QoI. For reasons explained shortly, we propose a separate expansion for the $P_i$:\n",
    "\n",
    "\\begin{align}\n",
    "    P_i = T_{i,1}(x,y;t) - \\sum^d_{j=2}c_{i,j}(t)T_{i,j}(x,y;t), \\quad i\\in\\{1,\\cdots, d\\}\n",
    "\\end{align}\n",
    "\n",
    "where the $T_{ij}$ are **user-specified** resolved quantities, discussed later. \n",
    "\n",
    "For illustrative purposes, let us assume we have 3 QoI, i.e. $d=3$. In this case there are 6 unknown $c_{i,j}$. Note that;\n",
    "\n",
    "* Each right-hand side of the 3 $Q_i$ ODEs contains an inner product between $\\partial q_i/\\partial \\omega$ and  $\\partial\\omega/\\partial t$ (remember that $q_i$ is the QoI integrand)\n",
    "\n",
    "* If we write $V_i:=\\partial q_i/\\partial \\omega$, the reduced SGS term $\\underline{r}$ at the PDE level generates a ODE SGS term (in each ODE separately) of the following form;\n",
    "\n",
    "\\begin{align}\n",
    "    \\left(V_i, \\underline{r}\\right) = \\tau_1\\left(V_i, P_1\\right) + \\tau_2\\left(V_i, P_2\\right) + \\tau_3\\left(V_i, P_3\\right),\\quad\\quad i \\in \\{1,2,3\\}.\n",
    "    \\label{eq:tmp1}\n",
    "\\end{align}\n",
    "\n",
    "This gives a total of 9 different $\\tau_k\\left(V_i, P_k\\right)$ terms, which is unnecessarily complicated. However, while choosing the $P_k$ basis remains a modelling step, one constraint we can impose to guide their formulation is a reduction in the number of $\\tau_k\\left(V_i, P_k\\right)$ terms. This can be achieved by imposing the following orthogonality conditions:\n",
    "\n",
    "\\begin{align}\n",
    "\\boxed{\n",
    "    \\left(V_i, P_j\\right) = 0\\;\\;\\mathrm{if}\\;\\;i\\neq j.}\n",
    "\\end{align}\n",
    "\n",
    "**In other words, the basis functions $P_j$ must be orthogonal to $\\partial q_i/\\partial\\omega^{\\mathcal{R}}$**. In the case of 3 QoI, the orthogonality constraints yield 6 linear equations, closing the system for the 6 unknown $c_{i,j}(t)$.  When we group these equations by $P_i$ we get 3 linear systems;\n",
    "\n",
    "\\begin{align}\n",
    "    \\begin{bmatrix}\n",
    "    \\left(V_{j_1}, T_{i,2}\\right) & \\left(V_{j_1}, T_{i,3}\\right) \\\\\n",
    "    \\left(V_{j_2}, T_{i,2}\\right) & \\left(V_{j_2}, T_{i,3}\\right)\n",
    "    \\end{bmatrix}\n",
    "    %\n",
    "    \\begin{bmatrix}\n",
    "    c_{i,2} \\\\\n",
    "    c_{i,3}\n",
    "    \\end{bmatrix} = \n",
    "    %\n",
    "    \\begin{bmatrix}\n",
    "    \\left(V_{j_1}, T_{i,1}\\right) \\\\\n",
    "    \\left(V_{j_2}, T_{i,1}\\right) \\\\\n",
    "    \\end{bmatrix},\\quad i\\in\\{1,2,3\\}.\n",
    "    \\label{eq:c_ij_sys3}\n",
    "\\end{align}\n",
    "\n",
    "Here, the index set $\\{j_1, j_2\\}$ is defined as $\\{j_1, j_2\\}:=\\{1,\\cdots, d\\}\\backslash\\{i\\}$, e.g.\\ as $\\{1,3\\}$ for $i=2$ and $d=3$. If we are tracking two QoI, the linear system reduces to 2 uncoupled algebraic equations that can be solved for $c_{i,2}$ as\n",
    "\n",
    "\\begin{align}\n",
    "    c_{i, 2} = \\frac{\\left(V_j, T_{i,1}\\right)}{\\left(V_j, T_{i,2}\\right)},\\quad\n",
    "    i\\in\\{1,2\\},\\quad j = \\{1,2\\}\\backslash\\{i\\}.\n",
    "    \\label{eq:c_ij_sys2}\n",
    "\\end{align}\n",
    "\n",
    "With orthogonality satisfied, the $Q_i$ ODE SGS term now consist of just 1 term per ODE;\n",
    "\n",
    "\\begin{align}\n",
    "    \\left(V_i, \\underline{r}\\right) = \\tau_i\\left(V_i, P_i\\right),\\quad i\\in\\{1,\\cdots,d\\}.\n",
    "    \\label{eq:src}\n",
    "\\end{align}\n",
    "\n",
    "The physical insight we gained is that for $Q_i$, $\\underline{r}$ results in a ODE SGS source term containing $\\left(V_i, P_i\\right)$, which can act to either dissipate or produce $Q_i$ at any given time. Therefore, in light of our goal to track the reference value of $Q_i$ (at least during the training phase), the task of $\\tau_i$ must be to switch on dissipation or production conditional on the value of $\\Delta Q_i:=\\mathcal{T}^{\\mathcal{R}} Q_i^{ref} - Q_i$. Hence, **closing the system at the ODE level implies finding a (data-driven) model for the $\\tau_i(t)$ times series, which should be a function of $\\Delta Q_i$.**\n",
    "\n",
    "Multiple $\\tau_i$ models are possible. A simple choice that seems to work well in practice thus far is to equate the ODE SGS term to $\\Delta Q_i$;\n",
    "\n",
    "\\begin{align}\n",
    "   \\boxed{\\tau_i\\left(V_i, P_i\\right) =  \\Delta Q_i,\\quad i\\in\\{1,\\cdots,d\\}}.\n",
    "\\end{align}\n",
    "\n",
    "This imposes a linear relaxation to the reference QoI value, and via $\\tau_i = \\Delta Q_i/\\left(V_i, P_i\\right)$, we obtain a training data set for the $\\tau_i$.\n",
    "\n",
    "Hence, instead of using the HR model to extract snapshots from the exact SGS term $\\overline{r}$, we generate **QoI specific training data** ($\\tau_i$) that is **reduced in size by a factor `N_LR ** 2 / d` compared to the full-field SGS term**. Typical values of `N_LR` are $2^6$, $2^7$ or higher. Hence, we obtain a reduction in the number of degrees of freedom of several orders of magnitude."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d8cc3f",
   "metadata": {},
   "source": [
    "### Specifying the $P_i$ basis\n",
    "\n",
    "We will demonstrate our approach by deriving a source term $\\underline{r}$ which tracks the reference energy $E$ and enstrophy $Z$ during training. The choice of the $Q_i$ dictates the choice of the $V_i$, due to $V_i:=\\partial q_i/\\partial\\omega$. For $E$ and $Z$ we must therefore set $V_1 = -\\Psi$ and $V_2 = \\omega$. On the other hand, the basis functions $T_{i,j}$ that make up the orthogonal basis functions $P_i$  *are a modelling choice*. While further research is required, for simplicity we will restrict the $T_{i,j}$ to the same set of terms that make up the $V_i$. Starting always with $T_{i,1} = V_i$, we get the following two-term expansion for the patterns $P_i$\n",
    "\n",
    "\\begin{align}\n",
    "    P_1 = -\\Psi - c_{1,2}\\omega\\quad\\mathrm{and}\\quad  P_2 = \\omega + c_{2,2}\\Psi.\n",
    "\\end{align}\n",
    "\n",
    "We find the values of the coefficients $c_{ij}$ (see above) as\n",
    "\n",
    "\\begin{align}\n",
    "    c_{1,2} = -\\frac{\\left(\\omega, \\Psi\\right)}{\\left(\\omega, \\omega\\right)} = \\frac{E}{Z}\n",
    "    \\quad\\mathrm{and}\\quad\n",
    "    c_{2,2} = -\\frac{\\left(\\Psi,\\omega\\right)}{\\left(\\Psi, \\Psi\\right)} = \\frac{E}{S},\n",
    "\\end{align}\n",
    "\n",
    "Here we have defined $S$ as the squared integrated stream function; $S:=\\left(\\Psi, \\Psi\\right)/2$. Thus, the total source term in the vorticity equation is\n",
    "\n",
    "\\begin{align}\n",
    "    \\underline{r} = -\\tau_1\\left( \\Psi + \\frac{E}{Z}\\omega\\right) + \n",
    "    \\tau_2\\left(\\omega + \\frac{E}{S}\\Psi\\right).\n",
    "\\end{align}\n",
    "The expressions for $\\tau_1$  and $\\tau_2$ are now;\n",
    "\n",
    "\\begin{align}\n",
    "     \\tau_1\\left(-\\Psi, P_1\\right) = 2\\tau_1\\left[S - \\frac{E^2}{Z}\\right] = \\Delta E, \\nonumber\\\\\n",
    "    \\tau_2\\left(\\omega, P_2\\right) = 2\\tau_2\\left[Z - \\frac{E^2}{S}\\right] =  \\Delta Z,\n",
    "\\end{align}\n",
    "\n",
    "Here, $\\Delta E :=\\mathcal{T}^{\\mathcal{R}}E^{ref} - E$ and $\\Delta Z := \\mathcal{T}^{\\mathcal{R}}Z^{ref} - Z$ are data extracted from the training database, where e.g.\\ ${T}^{\\mathcal{R}}Z^{ref}$ is the reference enstrophy computed with the projected reference vorticity $\\mathcal{T}^\\mathcal{R}\\omega^{ref}$. At any time $t_n$ during training, the values of $\\tau_1$ and $\\tau_2$ are found by \n",
    "\n",
    "\\begin{align}\n",
    "    \\tau_{1,n} = \\frac{1}{2}\\left[\\frac{\\Delta E_n}{S_n - E_n^2/Z_n}\\right]\n",
    "    \\quad\\mathrm{and}\\quad\n",
    "    \\tau_{2,n} = \\frac{1}{2}\\left[\\frac{\\Delta Z_n}{Z_n - E_n^2/S_n}\\right].\n",
    "    \\label{eq:2tau_n}\n",
    "\\end{align}\n",
    "\n",
    "Finally, after gathering all terms we get the following expression for the (full-field) reduced eddy forcing at $t_n$\n",
    "\n",
    "\\begin{align}\n",
    "\\boxed{\n",
    "    \\underline{r}_n = -\\frac{1}{2}\\left[\\frac{\\Delta E_n}{S_n - E_n^2/Z_n}\\right]\\left( \\Psi_n + \\frac{E_n}{Z_n}\\omega_n\\right) + \n",
    "    \\frac{1}{2}\\left[\\frac{\\Delta Z_n}{Z_n - E_n^2/S_n}\\right]\\left(\\omega_n + \\frac{E_n}{S_n}\\Psi_n\\right)}\n",
    "\\end{align}\n",
    "\n",
    "Replacing the exact SGS term $\\overline{r}$ with $\\underline{r}$ as defined above has **almost no influence on the quality of the energy and enstrophy solutions** [1]. Of course, there are no guarantees for any other quantities of interest, only those in the user-defined set $\\mathcal{Q}$ are explicitly tracked by the reduced SGS term. Again though, if we examine the $\\underline{r}$ expression, the only unclosed components are very small, namely $\\Delta E$ and $\\Delta Z$. A machine learned model for the unclosed components can therefore becomes significantly smaller as well.\n",
    "\n",
    "### References\n",
    "\n",
    "[1] Edeling, W., & Crommelin, D. (2020). Reducing data-driven dynamical subgrid scale models by physical constraints. Computers & Fluids, 201, 104470.\n",
    "\n",
    "[2] Peyret, R. (2002). Spectral methods for incompressible viscous flow (Vol. 148, pp. xii+-432). New York: Springer.\n",
    "\n",
    "### Tutorial\n",
    "In the tutorial below we will first run a short simulation with the exact SGS term, and subsequently we will replace $\\overline{r}$ with $\\underline{r}$. If you need to install EasySurrogate, uncomment the line below;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21f5e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to install easysurrogate\n",
    "#!pip install easysurrogate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d43d7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import easysurrogate as es\n",
    "import numpy as np\n",
    "from IPython import display\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "\n",
    "# This is the spectral solver as described above, stored locally in Vorticity_2D.py\n",
    "import Vorticity_2D as vort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3ad95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['image.cmap'] = 'seismic'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fe6d74",
   "metadata": {},
   "source": [
    "An EasySurrogate `Campaign` object is created, which mostly handles the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aadb1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an EasySurrogate campaign\n",
    "campaign = es.Campaign()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c42c663",
   "metadata": {},
   "source": [
    "Here we set the resolution of the high-resolution (HR) and low resolution (LR) resolved model. Note that `N_HR = 2 ** 7`, which is the number of points in 1 spatial direction. This does *not* qualify as running a direct numerical simulation, but this setting does allow us to demonstrate the approach while keeping the compute time suited for a interactive tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c779fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D spatial resolution low-res model\n",
    "N_LR = 2 ** 6\n",
    "# 1D spatial resolution high-res model\n",
    "N_HR = 2 ** 7\n",
    "# decay time in days for the Fourier mode of viscosity term, at cutoff scale. Used to determine nu.\n",
    "DECAY_TIME_NU = 5.0\n",
    "# decay time in days Fourier mode of forcing term, at cutoff scale. used to determine mu.\n",
    "DECAY_TIME_MU = 90.0\n",
    "# high-resolution (HR) time step\n",
    "DT_HR = 0.01\n",
    "# time step of low-resolution (LR) model as multiple of DT_HR\n",
    "DT_MULTIPLIER = 1\n",
    "DT_LR = DT_MULTIPLIER * DT_HR\n",
    "\n",
    "print(\"HR Resolution = %d x %d, LR resolution = %d x %d\" % (N_HR, N_HR, N_LR, N_LR,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb0b7bc",
   "metadata": {},
   "source": [
    "Here we create the HR solver:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd09960a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# high-res 2D Navier Stokes solver\n",
    "vort_solver_HR = vort.Vorticity_2D(N_HR, DT_HR, DECAY_TIME_NU, DECAY_TIME_MU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cf36fb",
   "metadata": {},
   "source": [
    "And the LR solver. We use the same $\\nu,\\mu$ values as in the HR model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4953eccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# low-res 2D Navier Stokes solver with the same nu, mu values as the HR solver.\n",
    "vort_solver_LR = vort.Vorticity_2D(N_LR, DT_LR, DECAY_TIME_NU, DECAY_TIME_MU, \n",
    "                                   nu = vort_solver_HR.nu, mu = vort_solver_HR.mu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ee5602",
   "metadata": {},
   "source": [
    "Below we visualize the $\\mathcal{\\hat{T}}^{\\mathcal{R}}$ spectral filter. Black corresponds to a 1, white to a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947d9072",
   "metadata": {},
   "outputs": [],
   "source": [
    "vort_solver_LR.plot_filter()\n",
    "filter_LR = vort_solver_LR.get_filter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d4e05a",
   "metadata": {},
   "source": [
    "We work with an input YAML file to load simulation settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77de2e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get simulation settings\n",
    "input_file = open(\"./inputs/input.yml\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355d07d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dict = yaml.safe_load(input_file)\n",
    "sim_settings = input_dict['sim_settings']\n",
    "for key in sim_settings.keys():\n",
    "    vars()[key] = sim_settings[key]\n",
    "    print(\"Setting %s to %s\" % (key, sim_settings[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2fc052",
   "metadata": {},
   "source": [
    "Below we determine when to start the simulation (`T=0` unless `RESTART=True`), and how long to simulate for. Here, `RESTART=True` and we load the `HR` and `LR` state at 365 days from the `restart folder`;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9b160e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# amount of non-dimensionalized time that corresponds to 1 simulated day (DAY = approx 2 * pi)\n",
    "DAY = vort_solver_LR.day\n",
    "# start time\n",
    "T = 365 * DAY\n",
    "# end time\n",
    "T_END = T + 100 * DAY\n",
    "# number of time steps between T and T_END\n",
    "n_steps = np.ceil((T_END - T) / DT_LR).astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a94ded",
   "metadata": {},
   "source": [
    "If `PLOT = True`, plot the solution to `fig` while running the simulation;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd555eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the solution while running\n",
    "if PLOT: \n",
    "    fig = plt.Figure(figsize=[10, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a33813",
   "metadata": {},
   "source": [
    "The `draw` subroutine that plots the simulation results;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590a1853",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw():\n",
    "    \"\"\"\n",
    "    Draws solution to screen while running the simulation.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None.\n",
    "\n",
    "    \"\"\"\n",
    "    fig.clf()\n",
    "    display.clear_output(wait=True) # required to make plot update work in Jupyter notebook\n",
    "\n",
    "    # contourplot Q1\n",
    "    ax1 = fig.add_subplot(221, title=r'')\n",
    "    try:\n",
    "        ax1.contourf(Q1, 50)\n",
    "    except NameError:\n",
    "        pass\n",
    "\n",
    "    # contourplot Q2\n",
    "    ax2 = fig.add_subplot(222)\n",
    "    ax2.contourf(Q2, 50)\n",
    "\n",
    "    # plot Q_HR and Q_LR\n",
    "    ax3 = fig.add_subplot(223)\n",
    "    ax3_2 = ax3.twinx()\n",
    "\n",
    "    try:\n",
    "        Q_HR = np.array(campaign.accum_data['Q_HR'])  \n",
    "        ax3.plot(Q_HR[:, 0], '.', label='HR', color='dodgerblue')\n",
    "        ax3_2.plot(Q_HR[:, 1], '.', color='dodgerblue')\n",
    "    except KeyError:\n",
    "        pass\n",
    "    \n",
    "    Q_LR = np.array(campaign.accum_data['Q_LR'])\n",
    "    ax3.plot(Q_LR[:, 0], label='LR', color='salmon')\n",
    "    ax3_2.plot(Q_LR[:, 1], color='salmon')\n",
    "\n",
    "    # plot the sgs term\n",
    "    ax4 = fig.add_subplot(224, title='SGS term')\n",
    "    ax4.contourf(sgs, 50)\n",
    "\n",
    "    display.display(fig) # required to make plot update work in Jupyter notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa42a35",
   "metadata": {},
   "source": [
    "Determine the rate at which to store / plot the solution, expressed in number of time steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e9c8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_frame_rate = np.floor(DAY / DT_LR).astype('int')\n",
    "store_frame_rate = np.floor(0.25 * DAY / DT_LR).astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc68fb0",
   "metadata": {},
   "source": [
    "If `RESTART=True` load a previous state from a file in the `./restart` directory. \n",
    "\n",
    "If `RESTART = False`, use the initial condition subroutine from `Vorticity_2D`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1b2474",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RESTART:\n",
    "    # load the HR state from a HDF5 file\n",
    "    IC_HR = campaign.load_hdf5_data(file_path=\n",
    "                                    './restart/state_HR_t%d_N%d.hdf5' % (T / DAY, DT_MULTIPLIER))\n",
    "    # HR vorticity at HR stencil k\n",
    "    w_hat_k_HR = IC_HR['w_hat_k_HR']\n",
    "    # HR vorticity at HR stencil k-1\n",
    "    w_hat_km1_HR = IC_HR['w_hat_km1_HR']\n",
    "    # HR Jacobian at HR stencil n-1\n",
    "    VgradW_hat_km1_HR = IC_HR['VgradW_hat_km1_HR']\n",
    "    # HR vorticity at LR stencil n\n",
    "    w_hat_n_HR = IC_HR['w_hat_n_HR']\n",
    "    # HR vorticity at LR stencil n - 1\n",
    "    w_hat_nm1_HR = IC_HR['w_hat_nm1_HR']\n",
    "\n",
    "    # load the LR state from a HDF5 file\n",
    "    IC_LR = campaign.load_hdf5_data(file_path=\n",
    "                                    './restart/state_LR_t%d_N%d.hdf5' % (T / DAY, DT_MULTIPLIER))\n",
    "    w_hat_n_LR = IC_LR['w_hat_n_LR']\n",
    "    w_hat_nm1_LR = IC_LR['w_hat_nm1_LR']\n",
    "    VgradW_hat_nm1_LR = IC_LR['VgradW_hat_nm1_LR']\n",
    "else:\n",
    "    # compute the HR initial condition stencil vorticity at HR step k and k-1\n",
    "    # and Jacobian at k-1\n",
    "    w_hat_k_HR, w_hat_km1_HR, VgradW_hat_km1_HR = vort_solver_HR.initial_cond()\n",
    "    # the corresponding HR values at the times of the LR stencil\n",
    "    w_hat_n_HR = w_hat_k_HR\n",
    "    w_hat_nm1_HR = w_hat_km1_HR\n",
    "    # compute the LR initial condition stencil vorticity at LR step n and n-1\n",
    "    # and Jacobian at n-1\n",
    "    w_hat_n_LR, w_hat_nm1_LR, VgradW_hat_nm1_LR = vort_solver_LR.initial_cond()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db3a387",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw():\n",
    "    \"\"\"\n",
    "    Draws solution to screen while running the simulation.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None.\n",
    "\n",
    "    \"\"\"\n",
    "    fig.clf()\n",
    "    display.clear_output(wait=True) # required to make plot update work in Jupyter notebook\n",
    "\n",
    "    # contourplot Q1\n",
    "    ax1 = fig.add_subplot(221, title=r'$\\omega$', xticks=[], yticks=[])\n",
    "    try:\n",
    "        ax1.contourf(Q1, 50)\n",
    "    except NameError:\n",
    "        pass\n",
    "\n",
    "    # contourplot Q2\n",
    "    ax2 = fig.add_subplot(222, title=r'$\\omega^{\\mathcal{R}}$', xticks=[], yticks=[])\n",
    "    ax2.contourf(Q2, 50)\n",
    "\n",
    "    # plot Q_HR and Q_LR\n",
    "    ax3 = fig.add_subplot(223, title=r'QoI', ylabel=r'$E$')\n",
    "    ax3_2 = ax3.twinx()\n",
    "    ax3_2.set_ylabel(r'Z')\n",
    "    \n",
    "    try:\n",
    "        Q_HR = np.array(campaign.accum_data['Q_HR'])  \n",
    "        ax3.plot(Q_HR[:, 0], '.', label='HR', color='dodgerblue')\n",
    "        ax3_2.plot(Q_HR[:, 1], '.', color='salmon')\n",
    "    except KeyError:\n",
    "        pass\n",
    "    \n",
    "    Q_LR = np.array(campaign.accum_data['Q_LR'])\n",
    "    ax3.plot(Q_LR[:, 0], label='LR', color='dodgerblue')\n",
    "    ax3_2.plot(Q_LR[:, 1], color='salmon')\n",
    "    ax3.legend()\n",
    "\n",
    "    # plot the sgs term\n",
    "    ax4 = fig.add_subplot(224, title='SGS term', xticks=[], yticks=[])\n",
    "    ax4.contourf(sgs, 50)\n",
    "\n",
    "    display.display(fig) # required to make plot update work in Jupyter notebook\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e31bc1",
   "metadata": {},
   "source": [
    "#### Defining Quantities of Interest\n",
    "\n",
    "As mentioned, our quantities of interest are $E$, and $Z$. This is read from the input file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fdbc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of QoI to track\n",
    "N_Q = input_dict['N_Q']\n",
    "print(\"Tracking %d QoI\" % (N_Q,))\n",
    "\n",
    "# get information on the Quantities of Interest\n",
    "QoI = {}\n",
    "for i in range(N_Q):\n",
    "    Q_key = \"Q%d\" % (i + 1)   #Q1, Q2 etc\n",
    "    QoI[Q_key] = input_dict[Q_key]\n",
    "    print(QoI[Q_key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12a8729",
   "metadata": {},
   "source": [
    "Below we find the subroutine to compute $E$ and $Z$, along with a subroutine to approximate the associated inner product $\\left(\\cdot, \\cdot\\right)$;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9614fa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quad(a_hat, b_hat):\n",
    "    \"\"\"\n",
    "    Perform quadrature using Fourier coefficients to approximate the inner product (a, b) / (2*pi)**2 2\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    a_hat : array (complex), shape (N, N)\n",
    "        The fourier coefficients of a(x, y).\n",
    "    b_hat : array (complex), shape (N, N)\n",
    "        The fourier coefficients of b(x, y).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The innner product (a, b) / (2*pi)* ** 2.\n",
    "\n",
    "    \"\"\"\n",
    "    N = a_hat.shape[0]\n",
    "    return np.dot(a_hat.flatten(), np.conjugate(b_hat.flatten())).real / N ** 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53697e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qoi_func(name, w_hat_n, _filter, **kwargs):\n",
    "    \"\"\"\n",
    "    Function which computes the spatially integrated quantities of interest.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    name : string\n",
    "        Name of the QoI\n",
    "    w_hat_n : array (complex), shape (N, N)\n",
    "        Vorticity Fourier coefficients.\n",
    "    _filter : array, shape (N, N)\n",
    "        The spectral filter used for calculating the QoI\n",
    "    **kwargs : array (complex)\n",
    "        Stream Function Fourier coefficients, passed as a keyword argument.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    qoi : array (real)\n",
    "        The spatially-integrated QoI\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    N = w_hat_n.shape[0]\n",
    "\n",
    "    # compute energy\n",
    "    if name == \"E\":\n",
    "        psi_hat_n = kwargs['psi_hat']\n",
    "        qoi = -0.5 * quad(_filter * psi_hat_n, w_hat_n)\n",
    "    # compute enstrophy\n",
    "    elif name == \"Z\":\n",
    "        qoi = 0.5 * quad(_filter * w_hat_n, w_hat_n)\n",
    "\n",
    "    return qoi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c5b6b0",
   "metadata": {},
   "source": [
    "### Create a reduced surrogate object\n",
    "\n",
    "This will create a reduced sgs object. Note that it is a limited implementation. It will work for 2D spectral solvers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a881de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a reduced SGS surrogate object\n",
    "surrogate = es.methods.Reduced_Surrogate(N_Q, N_LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3287bd47",
   "metadata": {},
   "source": [
    "### Running the simulation\n",
    "\n",
    "There is an input file `./inputs/input.yml`. To run a simulation with $\\overline{r}$ set the flag `EDDY_FORCING_TYPE` to `\"exact\"`. To overwrite $\\overline{r}$ with $\\underline{r}$, set `EDDY_FORCING_TYPE = \"reduced\"`. The solution is plotted to screen. You should note little difference in the evolution of $E$ and $Z$, yet a large difference in the appearance of the 2 SGS terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4015497f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time loop\n",
    "for n in tqdm(range(n_steps)):\n",
    "\n",
    "    if COMPUTE_REF:\n",
    "        # integrate the HR solver over DT_MULTIPLIER HR time steps\n",
    "        for i in range(DT_MULTIPLIER):\n",
    "            w_hat_kp1_HR, VgradW_hat_k_HR = vort_solver_HR.step(w_hat_k_HR, w_hat_km1_HR,\n",
    "                                                                VgradW_hat_km1_HR)\n",
    "            # update HR vars\n",
    "            w_hat_km1_HR = np.copy(w_hat_k_HR)\n",
    "            w_hat_k_HR = np.copy(w_hat_kp1_HR)\n",
    "            VgradW_hat_km1_HR = np.copy(VgradW_hat_k_HR)\n",
    "\n",
    "        # the HR vorticity at time t_n = n * DT_LR\n",
    "        w_hat_np1_HR = w_hat_kp1_HR\n",
    "\n",
    "        # exact sgs term\n",
    "        sgs_hat_exact = filter_LR * (vort_solver_HR.down_scale(VgradW_hat_km1_HR, N_LR) - VgradW_hat_nm1_LR)\n",
    "\n",
    "        # compute the HR stream function\n",
    "        psi_hat_n_HR = vort_solver_HR.compute_stream_function(w_hat_n_HR)\n",
    "\n",
    "        # compute the QoI using the HR state\n",
    "        Q_HR = np.zeros(N_Q)\n",
    "        for q in range(N_Q):\n",
    "            Q_key = \"Q%d\" % (q + 1,)\n",
    "            Q_HR[q] = qoi_func(QoI[Q_key]['name'],\n",
    "                               vort_solver_HR.down_scale(w_hat_n_HR, N_LR),\n",
    "                               filter_LR,\n",
    "                               psi_hat = vort_solver_HR.down_scale(psi_hat_n_HR, N_LR))\n",
    "\n",
    "    # compute the LR stream function\n",
    "    psi_hat_n_LR = vort_solver_LR.compute_stream_function(w_hat_n_LR)\n",
    "\n",
    "    # compute the QoI using the LR state\n",
    "    Q_LR = np.zeros(N_Q)\n",
    "    for q in range(N_Q):\n",
    "        Q_key = \"Q%d\" % (q + 1,)\n",
    "        Q_LR[q] = qoi_func(QoI[Q_key]['name'],\n",
    "                           w_hat_n_LR,\n",
    "                           filter_LR,\n",
    "                           psi_hat = psi_hat_n_LR)\n",
    "\n",
    "    # overwrite reduced sgs term with exact sgs term if True\n",
    "    if EDDY_FORCING_TYPE == \"exact\": \n",
    "        sgs_hat = sgs_hat_exact\n",
    "    elif EDDY_FORCING_TYPE == 'reduced':\n",
    "        # The QoI basis functions V_i = \\partial q_i / \\partial \\omega\n",
    "        V_i = []\n",
    "        for q in range(N_Q):\n",
    "            Q_key = \"Q%d\" % (q + 1,)\n",
    "            V_i.append(filter_LR * eval(QoI[Q_key]['V_i']))\n",
    "        \n",
    "        # compute the reduced subgrid-scale term\n",
    "        dQ = Q_HR - Q_LR\n",
    "        reduced_dict = surrogate.train(V_i, dQ)\n",
    "        sgs_hat = reduced_dict['sgs_hat']\n",
    "\n",
    "    # integrate the LR solver with sgs term\n",
    "    w_hat_np1_LR, VgradW_hat_n_LR = vort_solver_LR.step(w_hat_n_LR, w_hat_nm1_LR,\n",
    "                                                        VgradW_hat_nm1_LR,\n",
    "                                                        sgs_hat=sgs_hat)\n",
    "    # update LR vars\n",
    "    w_hat_nm1_LR = w_hat_n_LR\n",
    "    w_hat_n_LR = w_hat_np1_LR\n",
    "    VgradW_hat_nm1_LR = VgradW_hat_n_LR\n",
    "\n",
    "    if COMPUTE_REF:\n",
    "        # update HR vars on LR time stencil\n",
    "        w_hat_nm1_HR = w_hat_n_HR\n",
    "        w_hat_n_HR = w_hat_np1_HR\n",
    "\n",
    "    T += DT_LR\n",
    "    \n",
    "    # accumulate QoI data inside the EasySurrogate campaign\n",
    "    if np.mod(n, store_frame_rate) == 0:\n",
    "\n",
    "        campaign.accumulate_data({'Q_LR': Q_LR})\n",
    "        \n",
    "        if COMPUTE_REF: campaign.accumulate_data({'Q_HR': Q_HR})\n",
    "\n",
    "    # plot solution while running\n",
    "    if np.mod(n, plot_frame_rate) == 0 and PLOT:\n",
    "\n",
    "        if COMPUTE_REF: \n",
    "            Q1 = np.fft.ifft2(w_hat_np1_HR).real\n",
    "\n",
    "        Q2 = np.fft.ifft2(w_hat_np1_LR).real\n",
    "        sgs = np.fft.ifft2(sgs_hat).real\n",
    "        draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb78055",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
